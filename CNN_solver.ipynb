{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef555b8b",
   "metadata": {},
   "source": [
    "# CNN solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ea07a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer(msg='timer'):\n",
    "    tic = time()\n",
    "    yield\n",
    "    return print(f\"{msg}: {time() - tic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9be2ea",
   "metadata": {},
   "source": [
    "# Neural net solver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "93de5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetSolver(nn.Module):\n",
    "    def __init__(self, T_ini, K, s):\n",
    "        super(NeuralNetSolver,self).__init__()\n",
    "        self.nx = T_ini.shape[2]\n",
    "        self.ny = T_ini.shape[3]\n",
    "        self.T = nn.Parameter(T_ini[:,:,1:-1,1:-1])\n",
    "        self.K = K\n",
    "        self.s = s\n",
    "        dx = 1./(self.nx-1)\n",
    "        dy = 1./(self.ny-1)\n",
    "        self.grad_x = torch.tensor([-1./dx, 1./dx]).reshape((1,1,2,1))\n",
    "        self.grad_y = torch.tensor([ 1./dy,-1./dy]).reshape((1,1,1,2))\n",
    "        \n",
    "        self.avg_x = torch.tensor([.5,.5]).reshape((1,1,2,1))\n",
    "        self.avg_y = torch.tensor([.5,.5]).reshape((1,1,1,2))\n",
    "        \n",
    "        self.BC_left = torch.zeros((1,1,self.nx-2,1))\n",
    "        self.BC_right = torch.zeros((1,1,self.nx-2,1))\n",
    "        \n",
    "        self.BC_top = torch.zeros((1,1,1,self.ny))\n",
    "        self.BC_bot = torch.zeros((1,1,1,self.ny))\n",
    "        \n",
    "    def forward(self):\n",
    "        T = self.T\n",
    "        K = self.K\n",
    "        s = self.s\n",
    "        \n",
    "        # Add boundary conditions as padding\n",
    "        T = self.pad_T()\n",
    "        \n",
    "#         print(self.grad_x)\n",
    "        dT_dx = F.conv2d(T, self.grad_x)\n",
    "        dT_dy = F.conv2d(T, self.grad_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        K_avg_x = F.conv2d(K, self.avg_x)\n",
    "        K_avg_y = F.conv2d(K, self.avg_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        K_d2T_dx2 = F.conv2d(K_avg_x*dT_dx, self.grad_x)\n",
    "        K_d2T_dy2 = F.conv2d(K_avg_y*dT_dy, self.grad_y)\n",
    "        \n",
    "#         print(K_d2T_dx2.shape)\n",
    "#         print(K_d2T_dy2.shape)\n",
    "        \n",
    "        return K_d2T_dx2[:,:,:,1:-1] + K_d2T_dy2[:,:,1:-1,:] + s[:,:,1:-1,1:-1]\n",
    "    def pad_T(self):\n",
    "        T = self.T\n",
    "        T = torch.cat([self.BC_left, T, self.BC_right],dim=3)\n",
    "        T = torch.cat([self.BC_bot, T, self.BC_top],dim=2)\n",
    "        return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9686ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_hat):\n",
    "    # note: expected outcome is 0\n",
    "    return torch.mean((y_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccfbde",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "afde3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,loss_fn, optimizer, abs_loss_limit, rel_loss_limit):\n",
    "    \n",
    "    def closure():\n",
    "        out = net()\n",
    "        loss = loss_fn(out)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "      \n",
    "    last_loss = 0.0\n",
    "    with timer(\"solve\"):\n",
    "        print(f\"epoch  |  absolute loss  |  relative loss\")\n",
    "        print( \"---------------------------------------------\")\n",
    "        for i in range(500):\n",
    "            loss = optimizer.step(closure)\n",
    "            if (i%20)==0:\n",
    "                with torch.no_grad():\n",
    "                    loss = loss.item()\n",
    "                    print(f\" {i:04d}       {loss:.2e}          {abs(loss-last_loss):.2e}\")\n",
    "        #         \n",
    "        #             plt.title(f\"epoch = {i:.0f}, loss = {loss:.2e}\")\n",
    "        #             plt.imshow(net.T.reshape(net.T.shape[2:]))\n",
    "        #             display(fig)\n",
    "        #             clear_output(wait = True)\n",
    "                if loss<abs_loss_limit:\n",
    "                    print(f\"Stop! absolute loss target reached ({abs_loss_limit:.2e})\")\n",
    "                    break\n",
    "                elif abs(loss-last_loss)<rel_loss_limit:\n",
    "                    print(f\"Stop! relative loss target reached ({rel_loss_limit:.2e})\")\n",
    "                    break\n",
    "\n",
    "                last_loss = loss\n",
    "    return net.pad_T()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c596924",
   "metadata": {},
   "source": [
    "# Simple solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "81699cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  |  absolute loss  |  relative loss\n",
      "---------------------------------------------\n",
      " 0000       1.00e+00          1.00e+00\n",
      " 0020       8.78e-01          1.22e-01\n",
      " 0040       8.20e-01          5.79e-02\n",
      " 0060       7.79e-01          4.13e-02\n",
      " 0080       7.34e-01          4.46e-02\n",
      " 0100       7.16e-01          1.83e-02\n",
      " 0120       6.73e-01          4.30e-02\n",
      " 0140       6.29e-01          4.38e-02\n",
      " 0160       6.07e-01          2.18e-02\n",
      " 0180       5.97e-01          1.07e-02\n",
      " 0200       5.86e-01          1.07e-02\n",
      " 0220       5.80e-01          6.58e-03\n",
      " 0240       5.66e-01          1.40e-02\n",
      " 0260       5.27e-01          3.82e-02\n",
      " 0280       5.15e-01          1.28e-02\n",
      " 0300       4.45e-01          6.99e-02\n",
      " 0320       2.05e-01          2.39e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-343-606d8b6c3b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mT_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-332-9c723dac8073>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, loss_fn, optimizer, abs_loss_limit, rel_loss_limit)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"---------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                     \u001b[0mbe_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_stps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbe_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nx = 200\n",
    "ny = 200\n",
    "T_ini = torch.zeros((1,1,nx,ny))\n",
    "K     = torch.ones((1,1,nx,ny))\n",
    "s     = torch.ones((1,1,nx,ny))\n",
    "net = NeuralNetSolver(T_ini, K,s)\n",
    "\n",
    "optimizer = torch.optim.LBFGS(net.parameters())\n",
    "abs_loss = 1e-10\n",
    "rel_loss = 1e-100\n",
    "\n",
    "T_padded = train(net, loss_fn, optimizer, abs_loss, rel_loss)\n",
    "fig = plt.figure(figsize=[8,8])                \n",
    "with torch.no_grad():\n",
    "    plt.title(f\"epoch = {i:.0f}, loss = {loss:.2e}\")\n",
    "    plt.imshow(T_padded[0,0,:,:])\n",
    "    plt.colorbar()\n",
    "    display(fig)\n",
    "# clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ff3ab",
   "metadata": {},
   "source": [
    "# Multigrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "5c352b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4, 2, 1]\n",
      "200 200\n",
      "torch.Size([1, 1, 25, 25])\n",
      "epoch  |  absolute loss  |  relative loss\n",
      "---------------------------------------------\n",
      " 0000       1.00e+00          1.00e+00\n",
      " 0020       7.64e-10          1.00e+00\n",
      "Stop! absolute loss target reached (1.00e-06)\n",
      "solve: 0.41\n",
      "torch.Size([1, 1, 50, 50])\n",
      "epoch  |  absolute loss  |  relative loss\n",
      "---------------------------------------------\n",
      " 0000       3.25e-01          3.25e-01\n",
      " 0020       9.65e-06          3.25e-01\n",
      " 0040       9.65e-06          4.88e-09\n",
      "Stop! relative loss target reached (1.00e-07)\n",
      "solve: 1.37\n",
      "torch.Size([1, 1, 100, 100])\n",
      "epoch  |  absolute loss  |  relative loss\n",
      "---------------------------------------------\n",
      " 0000       3.28e-01          3.28e-01\n",
      " 0020       1.74e-05          3.28e-01\n",
      " 0040       1.58e-05          1.59e-06\n",
      " 0060       1.57e-05          1.14e-07\n",
      " 0080       1.56e-05          4.33e-08\n",
      "Stop! relative loss target reached (1.00e-07)\n",
      "solve: 5.16\n",
      "torch.Size([1, 1, 200, 200])\n",
      "epoch  |  absolute loss  |  relative loss\n",
      "---------------------------------------------\n",
      " 0000       3.29e-01          3.29e-01\n",
      " 0020       2.22e-05          3.29e-01\n",
      " 0040       2.04e-05          1.75e-06\n",
      " 0060       2.02e-05          1.91e-07\n",
      " 0080       2.11e-05          8.32e-07\n",
      " 0100       2.01e-05          9.80e-07\n",
      " 0120       2.00e-05          7.29e-08\n",
      "Stop! relative loss target reached (1.00e-07)\n",
      "solve: 51.33\n"
     ]
    }
   ],
   "source": [
    "nx, ny = 200, 200\n",
    "n_level = 4 # each level reduces resolution by a factor two\n",
    "reduction_fac = [2**(n_level-1-level) for level in range(n_level)]\n",
    "print(reduction_fac)\n",
    "# Material properties should be defined on the finest grid\n",
    "K_ref     = torch.ones((1,1,nx,ny))\n",
    "s_ref     = torch.ones((1,1,nx,ny))\n",
    "print(nx, ny)\n",
    "\n",
    "n_level = 3\n",
    "for level, red_fac in enumerate(reduction_fac):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        K = torch.nn.functional.avg_pool2d(K_ref, red_fac, stride=red_fac)\n",
    "        s = torch.nn.functional.avg_pool2d(s_ref, red_fac, stride=red_fac)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if level==0:\n",
    "        T_ini = torch.zeros((1,1,int(nx/red_fac),int(ny/red_fac)))\n",
    "    else:\n",
    "        \n",
    "        T_ini = F.interpolate(T_previous,scale_factor=2,mode='bilinear',align_corners=True)\n",
    "    print(T_ini.shape)\n",
    "                \n",
    "            \n",
    "        \n",
    "\n",
    "    net = NeuralNetSolver(T_ini, K,s)\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(net.parameters())\n",
    "    abs_loss = 1e-6\n",
    "    rel_loss = 1e-7\n",
    "\n",
    "    \n",
    "    T_previous = train(net, loss_fn, optimizer, abs_loss, rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302dfb43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
